<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Introduction to Machine Learning | Jiahao Peng</title>
  <meta name="author" content="me">
  
  <meta name="description" content="本篇笔记是大一时入门机器学习所写，听的是吴恩达的机器学习入门课程。由于课程是英文课程，所以笔记也是英文的。现在看来当时的写作水平十分生涩。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Introduction to Machine Learning"/>
  <meta property="og:site_name" content="Jiahao Peng"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/atom.xml" title="Jiahao Peng" type="application/atom+xml">
  
  
    <link href="/favicon.png" rel="icon">
  

  <!-- CSS -->
  <link rel="stylesheet" href="/css/themes/bootstrap.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight-default.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/comment.css" media="screen" type="text/css">
  <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
	<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.7/es5-sham.min.js"></script>
  <![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>
  
  
  <!-- analytics -->
  



<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <nav id="main-nav" class="navbar  navbar-default navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
	<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
       <a class="navbar-brand" href="/">Jiahao Peng</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
    <div class="content">
      


	
		<div class="page-header ">		
			<h1 class="title "> Introduction to Machine Learning</h1>
		</div>		
	






<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  
		 <div class="alert alert-success description">
			<i class="fa fa-info-circle"></i> <p>本篇笔记是大一时入门机器学习所写，听的是吴恩达的机器学习入门课程。由于课程是英文课程，所以笔记也是英文的。现在看来当时的写作水平十分生涩。</p>
			
		 </div> <!-- alert -->
	  		

	  <h2 id="definition">01 Definition</h2>
<ul>
<li>Machine Learning: Field of study that gives computers the ability to
learn without being explicitly programmed. — Arthur Samuel</li>
<li>Well-posed Learning Problem: <span
class="math inline"><em>A</em></span> compouter program is said to learn
from experience <span class="math inline"><em>E</em></span> with respect
to some task <span class="math inline"><em>T</em></span> and some
performance measure <span class="math inline"><em>P</em></span>, if its
performance on <span class="math inline"><em>T</em></span>, as measured
by <span class="math inline"><em>P</em></span>, imporoves with
experience <span class="math inline"><em>E</em></span>. — Tom
Mitchell</li>
<li>Machine Learning algorithms:
<ul>
<li>Supervised learning</li>
<li>Unsupervised learning</li>
<li>Others: Reinforcement learning, recommender systems</li>
</ul></li>
</ul>
<span id="more"></span>
<h2 id="two-types-of-learning">02 Two Types of Learning</h2>
<p>There are two major types of learning —— supervised learning and
unsupervised learning.</p>
<h3 id="supervised-learning">2.1 Supervised Learning</h3>
<ul>
<li>Definition: The term supervised learning refers to the fact that we
give the algorithm a dataset in which the “right answer” are given.</li>
<li>Category
<ul>
<li>Regression: Predict continuous valued output</li>
<li>Classification: Give discrete valued outout</li>
</ul></li>
</ul>
<h3 id="unsupervised-learning">2.2 Unsupervised learning</h3>
<ul>
<li>Definition: Give the algorithm a bunch of data without any explicit
instruciton or imformation, but require it to categorize the data into
different clusters automatically.</li>
</ul>
<h2 id="linear-regression">03 Linear Regression</h2>
<ul>
<li>Definition
<ul>
<li>Regression analysis is a statistical analysis method to determine
the interdependent quantitative relationship between two or more
variables.</li>
<li>According to the number of variables involved, regression analysis
can be divided into univariate regression and multivariate regression
analysis.</li>
</ul></li>
</ul>
<p>The following example is a classic linear regression problem ——
Portland housing price prediction.</p>
<p><img src="/img/Introduction-to-Machine-Learning-01.png" /></p>
<p>The exact figures are examplified like:</p>
<p><img src="/img/Introduction-to-Machine-Learning-02.png" /></p>
<p>We are going to analyse the above data of housing prices from the
city of Portland, Oregan to predict the posibble price of a house
according to its size based on the analysis result. It’s a clear
supervised learning (regression) problem.</p>
<p>So the algorithm is aimed to find a hypothesis function through
quantities of data, and the function will map <span
class="math inline"><em>x</em></span> (size of house) to <span
class="math inline"><em>y</em></span> (estimated price) to get the
correct answer. The whole process can be illustrated by the graph
below.</p>
<p><img src="/img/Introduction-to-Machine-Learning-03.png" /></p>
<p>For there is only one variate (size of house) in this model, we call
it <strong>univariate</strong> linear regression.</p>
<h2 id="cost-function">04 Cost Function</h2>
<p>Let’s continue with the example of housing price prediction. Assume
the <span class="math inline"><em>m</em></span> equals 47, which
represents the number of training examples. And the hypothesis function
is as below (a univariate linear function): <span
class="math display"><em>h</em><sub><em>θ</em></sub>(<em>x</em>) = <em>θ</em><sub>0</sub> + <em>θ</em><sub>1</sub><em>x</em></span>
These <span class="math inline"><em>θ</em><sub>0</sub></span> and <span
class="math inline"><em>θ</em><sub>1</sub></span> are called the
parameters of the model.</p>
<p>So the idea is to choose the appropriate <span
class="math inline"><em>θ</em><sub>0</sub></span> and <span
class="math inline"><em>θ</em><sub>1</sub></span> so that <span
class="math inline"><em>h</em><sub><em>θ</em></sub>(<em>x</em>)</span>
can be approximated to the <span class="math inline"><em>y</em></span>
for our examples <span
class="math inline">(<em>x</em>,<em>y</em>)</span>, which is to say that
we want the difference between <span
class="math inline"><em>h</em>(<em>x</em>)</span> and <span
class="math inline"><em>y</em></span> to be small, i.e. minimize <span
class="math display">$$
J(\theta_0,\theta_1)=\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2
$$</span> The above function <span
class="math inline"><em>J</em>(<em>θ</em><sub>0</sub>,<em>θ</em><sub>1</sub>)</span>
is what we called Cost Function. And our goal is to minimize its result
by finding the best values for <span
class="math inline"><em>θ</em><sub>0</sub></span> and <span
class="math inline"><em>θ</em><sub>1</sub></span>.</p>
<p>The relation between the hypothesis function and the cost
function:</p>
<ul>
<li>The hypothesis function <span
class="math inline"><em>h</em><sub><em>θ</em></sub>(<em>x</em>)</span>
is a function of <span class="math inline"><em>x</em></span> for fixed
<span class="math inline"><em>θ</em></span>, while the cost function
<span
class="math inline"><em>J</em>(<em>θ</em><sub>0</sub>,<em>θ</em><sub>1</sub>)</span>
is of the parameter <span
class="math inline"><em>θ</em><sub>0</sub></span> and <span
class="math inline"><em>θ</em><sub>1</sub></span>.</li>
<li>By <span
class="math inline"><em>J</em>(<em>θ</em><sub>0</sub>,<em>θ</em><sub>1</sub>)</span>
we obtain the accurate <span class="math inline"><em>θ</em></span> we
want so that we can figure out <span
class="math inline"><em>h</em><sub><em>θ</em></sub>(<em>x</em>)</span>,
which is our final goal.</li>
</ul>
<h2 id="gradient-descent">05 Gradient Descent</h2>
<p>Let’s visualize the funtction <span
class="math inline"><em>J</em>(<em>θ</em><sub>0</sub>,<em>θ</em><sub>1</sub>)</span>
to better understand it:</p>
<p><img src="/img/Introduction-to-Machine-Learning-04.png" /></p>
<p>Imagine that the figure is a huge mountain and you are standing on
one point of it. Then think: which direction should I step in if I want
to physically walk down this mountain as quickly as possible? Once you
have determined the direction, you take your step and then stop to think
again: what direction should I take that step in next? Keep walking and
keep asking until you converge to this local minimum as the following
figure shows.</p>
<p><img src="/img/Introduction-to-Machine-Learning-05.png" /></p>
<p>The whole process is what we called <strong>Gradient
Descent</strong>.</p>
<p>The following algorithm gives the mathematical form of gradient
descent, which is not difficult to understand so I skip its
explaination.</p>
<p><img src="/img/Introduction-to-Machine-Learning-06.png" /></p>
<h2 id="gradient-descent-for-linear-regression">06 Gradient Descent for
Linear Regression</h2>
<p>What if we want to apply gradient descent to linear regression?</p>
<p><img src="/img/Introduction-to-Machine-Learning-07.png" /></p>
<p>It is pretty easy actually. All we need to do is to take the
derivatives of the <span
class="math inline"><em>θ</em><sub>0</sub></span> and <span
class="math inline"><em>θ</em><sub>1</sub></span> in the cost function
separately and substitute the derivatives into the gradient descent
algorithm. The algorithm below shows the gradient descent for linear
regression.</p>
<p><img src="/img/Introduction-to-Machine-Learning-08.png" /></p>
<p>When we implement the algorithm, the cost function is approaching the
optimum and the hypothesis function is getting more and more in line
with our dataset. The illustration below shows the visualization of the
process.</p>
<p><img src="/img/Introduction-to-Machine-Learning-09.png" /></p>
<p>If we accumulate the gradients of a small batch of data samples to
update the parameters at once, then we get <strong>Batch</strong>
Gradient Descent.</p>
	  
	</div>

	<!-- recommended posts -->
	

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
				
		<li class="prev"><a href="/2022/07/21/Linear-Regression-with-Multiple-Variables/" class="alignleft prev"><i class="fa fa-arrow-circle-o-left"></i>Prev</a></li>
  		

        <li><a href="/archives"><i class="fa fa-archive"></i>Archive</a></li>

		
          <li class="next disabled"><a>Next<i class="fa fa-arrow-circle-o-right"></i></a></li>
        
	
</ul>
</div>

    </center>
	</div>

    <!-- share -->
    
        
    <div class="bdsharebuttonbox">
        <a href="#" class="bds_more" data-cmd="more"></a>
        <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
        <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
        <a href="#" class="bds_fbook" data-cmd="fbook" title="分享到Facebook"></a>
        <a href="#" class="bds_twi" data-cmd="twi" title="分享到Twitter"></a>
        <a href="#" class="bds_linkedin" data-cmd="linkedin" title="分享到linkedin"></a>
        <a href="#" class="bds_evernotecn" data-cmd="evernotecn" title="分享到印象笔记"></a>
        <a href="#" class="bds_youdao" data-cmd="youdao" title="分享到有道云笔记"></a>
        <a href="#" class="bds_copy" data-cmd="copy" title="分享到复制网址"></a>
    </div>
    <script>
        window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"1","bdSize":"24"},"share":{}};
        with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
    </script>


        

    
	
	<!-- comment -->
	
<section id="comment">
  <h2 class="title">Comments</h2>
  
</section>


	</div> <!-- col-md-9/col-md-12 -->
		
	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2022-07-21 
	</div>
	

	<!-- categories -->
    
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#categorys"><i class="fa fa-folder"></i></a>	
    <ul id="categorys" class="tag_box list-unstyled collapse in">
          
  <li>
    <li><a href="/categories/Machine-Learning-Andrew-Ng/">Machine Learning - Andrew Ng<span>4</span></a></li>
  </li>

    </ul>
	</div>
	

	<!-- tags -->
	
	<div class="meta-widget">
	<a data-toggle="collapse" data-target="#tags"><i class="fa fa-tags"></i></a>		  
    <ul id="tags" class="tag_box list-unstyled collapse in">	  
	    
  <li><a href="/tags/machine-learning/">machine learning<span>5</span></a></li>

    </ul>
	</div>
	

	<!-- toc -->
	<div class="meta-widget">
	
	   <a data-toggle="collapse" data-target="#toc"><i class="fa fa-bars"></i></a>
	   <div id="toc" class="toc collapse in">
			<ol class="toc-article"><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#definition"><span class="toc-article-text">01 Definition</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#two-types-of-learning"><span class="toc-article-text">02 Two Types of Learning</span></a><ol class="toc-article-child"><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#supervised-learning"><span class="toc-article-text">2.1 Supervised Learning</span></a></li><li class="toc-article-item toc-article-level-3"><a class="toc-article-link" href="#unsupervised-learning"><span class="toc-article-text">2.2 Unsupervised learning</span></a></li></ol></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#linear-regression"><span class="toc-article-text">03 Linear Regression</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#cost-function"><span class="toc-article-text">04 Cost Function</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#gradient-descent"><span class="toc-article-text">05 Gradient Descent</span></a></li><li class="toc-article-item toc-article-level-2"><a class="toc-article-link" href="#gradient-descent-for-linear-regression"><span class="toc-article-text">06 Gradient Descent for
Linear Regression</span></a></li></ol>
		</div>
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

	</div>
		

</div><!-- row -->




    </div>
  </div>
  <div class="container-narrow">
    <footer> <!--<p>
  &copy; 2025 me
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a target="_blank" rel="noopener" href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p>-->
 </footer>
  </div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>


<!-- syntax highlighting -->


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
	<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</html>